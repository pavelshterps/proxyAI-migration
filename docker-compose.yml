version: '3.8'

services:
  db:
    image: postgres:14-alpine
    container_name: proxyai_db
    env_file: .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - proxyai_net

  redis:
    image: redis:7-alpine
    container_name: proxyai_redis
    env_file: .env
    command:
      - redis-server
      - --requirepass
      - "${REDIS_PASSWORD}"
      - --masterauth
      - "${REDIS_PASSWORD}"
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - proxyai_net
    restart: unless-stopped

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: proxyai_api
    env_file: .env
    command: >
      sh -c "until nc -z db 5432; do sleep 1; done;
             uvicorn main:app --host 0.0.0.0 --port 8000 --workers ${API_WORKERS}"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - REDIS_URL=${REDIS_URL}
      - UPLOAD_FOLDER=${UPLOAD_FOLDER}
      - RESULTS_FOLDER=${RESULTS_FOLDER}
      - DIARIZER_CACHE_DIR=${DIARIZER_CACHE_DIR}
      - HUGGINGFACE_CACHE_DIR=${HUGGINGFACE_CACHE_DIR}
      - WHISPER_MODEL_PATH=${WHISPER_MODEL_PATH}
      - WHISPER_DEVICE=${WHISPER_DEVICE}
      - WEBHOOK_URL=${WEBHOOK_URL}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
    volumes:
      - ./:/app:delegated
      - upload_data:${UPLOAD_FOLDER}
      - results_data:${RESULTS_FOLDER}
      - diarizer_cache:${DIARIZER_CACHE_DIR}
      - ./data/hf_cache:/hf_cache
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
    networks:
      - proxyai_net
    restart: unless-stopped

  worker_cpu:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: proxyai_worker_cpu
    env_file: .env
    command:
      - celery
      - -A
      - celery_app:app
      - worker
      - --loglevel=info
      - --concurrency=${CPU_CONCURRENCY}
      - --queues=transcribe_cpu
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - REDIS_URL=${REDIS_URL}
      - UPLOAD_FOLDER=${UPLOAD_FOLDER}
      - RESULTS_FOLDER=${RESULTS_FOLDER}
      - DIARIZER_CACHE_DIR=${DIARIZER_CACHE_DIR}
      - HUGGINGFACE_CACHE_DIR=${HUGGINGFACE_CACHE_DIR}
      - WHISPER_MODEL_PATH=${WHISPER_MODEL_PATH}
      - WHISPER_DEVICE=cpu
      - WEBHOOK_URL=${WEBHOOK_URL}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
    volumes:
      - ./:/app:delegated
      - upload_data:${UPLOAD_FOLDER}
      - results_data:${RESULTS_FOLDER}
      - diarizer_cache:${DIARIZER_CACHE_DIR}
      - ./data/hf_cache:/hf_cache
    depends_on:
      - api
      - redis
    networks:
      - proxyai_net
    restart: unless-stopped

  worker_gpu_1:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    container_name: proxyai_worker_gpu_1
    runtime: nvidia
    mem_limit: 8g
    env_file: .env
    command:
      - celery
      - -A
      - celery_app:app
      - worker
      - -E
      - --loglevel=info
      - --concurrency=${GPU_CONCURRENCY}
      - --prefetch-multiplier=1
      - --max-tasks-per-child=10
      - --queues=transcribe_gpu,diarize_gpu
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - REDIS_URL=${REDIS_URL}
      - UPLOAD_FOLDER=${UPLOAD_FOLDER}
      - RESULTS_FOLDER=${RESULTS_FOLDER}
      - DIARIZER_CACHE_DIR=${DIARIZER_CACHE_DIR}
      - HUGGINGFACE_CACHE_DIR=${HUGGINGFACE_CACHE_DIR}
      - WHISPER_MODEL_PATH=${WHISPER_MODEL_PATH}
      - WHISPER_DEVICE=cuda
      - NVIDIA_VISIBLE_DEVICES=0
      - WEBHOOK_URL=${WEBHOOK_URL}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
    volumes:
      - ./:/app:delegated
      - upload_data:${UPLOAD_FOLDER}
      - results_data:${RESULTS_FOLDER}
      - diarizer_cache:${DIARIZER_CACHE_DIR}
      - ./data/hf_cache:/hf_cache
    depends_on:
      - api
      - redis
    networks:
      - proxyai_net
    restart: unless-stopped

  worker_gpu_2:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    container_name: proxyai_worker_gpu_2
    runtime: nvidia
    mem_limit: 8g
    env_file: .env
    command:
      - celery
      - -A
      - celery_app:app
      - worker
      - -E
      - --loglevel=info
      - --concurrency=${GPU_CONCURRENCY}
      - --prefetch-multiplier=1
      - --max-tasks-per-child=12
      - --queues=transcribe_gpu,diarize_gpu
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - REDIS_URL=${REDIS_URL}
      - UPLOAD_FOLDER=${UPLOAD_FOLDER}
      - RESULTS_FOLDER=${RESULTS_FOLDER}
      - DIARIZER_CACHE_DIR=${DIARIZER_CACHE_DIR}
      - HUGGINGFACE_CACHE_DIR=${HUGGINGFACE_CACHE_DIR}
      - WHISPER_MODEL_PATH=${WHISPER_MODEL_PATH}
      - WHISPER_DEVICE=cuda
      - NVIDIA_VISIBLE_DEVICES=0
      - WEBHOOK_URL=${WEBHOOK_URL}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
    volumes:
      - ./:/app:delegated
      - upload_data:${UPLOAD_FOLDER}
      - results_data:${RESULTS_FOLDER}
      - diarizer_cache:${DIARIZER_CACHE_DIR}
      - ./data/hf_cache:/hf_cache
    depends_on:
      - api
      - redis
    networks:
      - proxyai_net
    restart: unless-stopped

  worker_webhooks:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: proxyai_worker_webhooks
    env_file: .env
    command:
      - celery
      - -A
      - celery_app:app
      - worker
      - --loglevel=info
      - --concurrency=2
      - --queues=webhooks
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - REDIS_URL=${REDIS_URL}
      - WEBHOOK_URL=${WEBHOOK_URL}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
    volumes:
      - ./:/app:delegated
    depends_on:
      - api
      - redis
    networks:
      - proxyai_net
    restart: unless-stopped

  beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: proxyai_beat
    env_file: .env
    command:
      - celery
      - -A
      - celery_app:app
      - beat
      - --loglevel=info
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - REDIS_URL=${REDIS_URL}
    volumes:
      - ./:/app:delegated
    depends_on:
      - redis
    networks:
      - proxyai_net
    restart: unless-stopped

  flower:
    image: mher/flower:0.9.7
    container_name: proxyai_flower
    env_file: .env
    command: >
      sh -c "chown -R 1000:1000 /var/lib/flower \
             && flower --broker=${CELERY_BROKER_URL} \
                       --broker_api=${CELERY_BROKER_URL} \
                       --address=0.0.0.0 \
                       --basic_auth=${FLOWER_USER}:${FLOWER_PASS} \
                       --port=5555 \
                       --persistent=True \
                       --db=/var/lib/flower/flower.db"
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - REDIS_URL=${REDIS_URL}
    volumes:
      - flower_db:/var/lib/flower
    ports:
      - "5555:5555"
    depends_on:
      - redis
    networks:
      - proxyai_net
    restart: unless-stopped

  celery_exporter:
    image: danihodovic/celery-exporter:latest
    container_name: proxyai_celery_exporter
    env_file: .env
    environment:
      - METRICS_PORT=9808
    command: ["--broker-url=${CELERY_BROKER_URL}"]
    ports:
      - "9808:9808"
    depends_on:
      - redis
      - worker_cpu
      - worker_gpu_1
      - worker_gpu_2
    networks:
      - proxyai_net
    restart: unless-stopped

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: proxyai_cadvisor
    privileged: true
    pid: "host"
    ports:
      - "8082:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys:/sys:ro
      - /sys/fs/cgroup:/sys/fs/cgroup:ro
      - /var/lib/docker/:/var/lib/docker/:ro
    networks:
      - proxyai_net
    restart: unless-stopped

  node_exporter:
    image: prom/node-exporter:latest
    container_name: proxyai_node_exporter
    ports:
      - "9100:9100"
    networks:
      - proxyai_net
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: proxyai_prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    depends_on:
      - celery_exporter
      - cadvisor
      - api
      - node_exporter
    networks:
      - proxyai_net
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: proxyai_grafana
    env_file: .env
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASS}
    volumes:
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - proxyai_net
    restart: unless-stopped

  nginx:
    image: nginx:stable-alpine
    container_name: proxyai_nginx
    depends_on:
      - api
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - /etc/letsencrypt/live/tonage.io/fullchain.pem:/etc/nginx/certs/fullchain.pem:ro
      - /etc/letsencrypt/live/tonage.io/privkey.pem:/etc/nginx/certs/privkey.pem:ro
    networks:
      - proxyai_net
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  upload_data:
  results_data:
  diarizer_cache:
  flower_db:
  grafana_data:

networks:
  proxyai_net:
    driver: bridge
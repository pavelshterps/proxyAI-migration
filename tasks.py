# tasks.py

import os
import json
import logging
from celery import Celery, signals
from celery.utils.log import get_task_logger
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from faster_whisper import WhisperModel
from pyannote.audio import Pipeline as DiarizationPipeline
from config.settings import settings
from crud import update_upload_status

logger = get_task_logger(__name__)

# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Celery-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = Celery("proxyai")
app.config_from_object("config.celery")

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ SQLAlchemy –∏ —Ñ–∞–±—Ä–∏–∫–∞ —Å–µ—Å—Å–∏–π
engine = create_async_engine(settings.DATABASE_URL, echo=False, future=True)
AsyncSessionLocal = sessionmaker(
    engine, expire_on_commit=False, class_=AsyncSession
)

_whisper: WhisperModel | None = None
_diarizer: DiarizationPipeline | None = None

@signals.worker_process_init.connect
def preload_and_warmup(**kwargs):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω Pyannote –Ω–∞ CPU –∏ quantized Whisper –Ω–∞ GPU
    –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ HuggingFace.
    """
    global _whisper, _diarizer

    # 1) –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ CPU
    try:
        _diarizer = DiarizationPipeline.from_pretrained(
            settings.PYANNOTE_PIPELINE,
            use_auth_token=settings.HUGGINGFACE_TOKEN
        )
        logger.info(f"‚úÖ Loaded diarization pipeline `{settings.PYANNOTE_PIPELINE}`")
    except Exception as e:
        logger.error(f"‚ùå Failed to load diarization pipeline: {e}")
        raise

    # 2) Whisper –Ω–∞ GPU (quantized –º–æ–¥–µ–ª—å —É–∂–µ –≤ settings.WHISPER_MODEL_PATH)
    model_path = settings.WHISPER_MODEL_PATH
    whisper_init_kwargs = {
        "device": settings.WHISPER_DEVICE,
        "compute_type": settings.WHISPER_COMPUTE_TYPE,
        # ctranslate2.models.Whisper __init__ –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç batch_size –∏ cache_dir
    }
    try:
        _whisper = WhisperModel(model_path, **whisper_init_kwargs)
        logger.info(f"‚úÖ Loaded Whisper model from `{model_path}`")
    except Exception as e:
        logger.error(f"‚ùå Failed to load Whisper model: {e}")
        raise

@app.task(
    bind=True,
    name="process_audio",
    acks_late=True,
    autoretry_for=(Exception,),
    retry_backoff=True,
    retry_kwargs={"max_retries": 3},
)
async def process_audio(self, upload_id: int, file_path: str):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞:
    1) –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ processing,
    2) –ø—Ä–æ–≥–Ω–∞—Ç—å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é,
    3) –ø—Ä–æ–≥–Ω–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ —Å batch_size,
    4) —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON,
    5) –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ completed/failed,
    6) —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª—ã.
    """
    session = AsyncSessionLocal()
    json_path = f"{file_path}.json"
    try:
        # —Å—Ç–∞—Ç—É—Å ‚Üí processing
        await update_upload_status(session, upload_id, "processing")

        # 1) –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è
        diarization = _diarizer({"uri": file_path, "audio": file_path})
        segments = [
            {"start": turn.start, "end": turn.end, "speaker": speaker}
            for turn, _, speaker in diarization.itertracks(yield_label=True)
        ]

        # 2) –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å batch_size
        transcriptions = []
        for seg in segments:
            result = _whisper.transcribe(
                file_path,
                language=settings.WHISPER_LANGUAGE,
                word_timestamps=False,
                segment=seg,
                batch_size=settings.WHISPER_BATCH_SIZE,
            )
            text = " ".join([s.text for s in result])
            transcriptions.append({**seg, "text": text})

        # 3) –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(transcriptions, f, ensure_ascii=False, indent=2)
        logger.info(f"üìÑ Saved transcription JSON to {json_path}")

        # 4) –£—Å–ø–µ—à–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        await update_upload_status(session, upload_id, "completed")
        logger.info(f"‚úÖ Upload {upload_id} completed")

    except Exception as e:
        logger.exception(f"üî• Error in process_audio (upload_id={upload_id}): {e}")
        # —Å—Ç–∞—Ç—É—Å ‚Üí failed
        try:
            await update_upload_status(session, upload_id, "failed")
        except Exception as ee:
            logger.error(f"‚ùå Failed to mark upload {upload_id} as failed: {ee}")
        raise

    finally:
        # –í—Å–µ–≥–¥–∞ —É–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –∏ JSON
        cleanup_files(file_path, json_path)
        await session.close()

def cleanup_files(*paths: str):
    """–£–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª—ã –ø–æ —Å–ø–∏—Å–∫—É –ø—É—Ç–µ–π, –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    for p in paths:
        try:
            os.remove(p)
            logger.info(f"üóëÔ∏è Deleted file {p}")
        except FileNotFoundError:
            logger.warning(f"‚ö†Ô∏è File not found for deletion: {p}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to delete {p}: {e}")